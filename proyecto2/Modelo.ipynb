{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creaci√≥n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from packaging import version\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los datos\n",
    "df = pd.read_csv(\"./NuevoData.csv\", delimiter=',')\n",
    "\n",
    "df_mdl = df[[\"LIMIT_BAL\", \"SEX\", \"AGE\", \"_1\", \"_2\", \"_3\", \"_4\", \"MARRIAGE_1\", \"MARRIAGE_2\", \"MARRIAGE_3\", \"default payment next month\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mdl.iloc[:, :-1] \n",
    "Y = tf.keras.utils.to_categorical(df_mdl.iloc[:, -1], num_classes=2)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18944, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(5, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67 (268.00 Byte)\n",
      "Trainable params: 67 (268.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 2s 3ms/step - loss: 12.3174 - accuracy: 0.7748 - val_loss: 0.6232 - val_accuracy: 0.7827\n",
      "Epoch 2/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.6043 - accuracy: 0.7759 - val_loss: 0.5836 - val_accuracy: 0.7827\n",
      "Epoch 3/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5752 - accuracy: 0.7759 - val_loss: 0.5607 - val_accuracy: 0.7827\n",
      "Epoch 4/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7759 - val_loss: 0.5471 - val_accuracy: 0.7827\n",
      "Epoch 5/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5483 - accuracy: 0.7759 - val_loss: 0.5388 - val_accuracy: 0.7827\n",
      "Epoch 6/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7759 - val_loss: 0.5336 - val_accuracy: 0.7827\n",
      "Epoch 7/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7759 - val_loss: 0.5303 - val_accuracy: 0.7827\n",
      "Epoch 8/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7759 - val_loss: 0.5281 - val_accuracy: 0.7827\n",
      "Epoch 9/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7759 - val_loss: 0.5267 - val_accuracy: 0.7827\n",
      "Epoch 10/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 0.5338 - accuracy: 0.7759 - val_loss: 0.5258 - val_accuracy: 0.7827\n",
      "Epoch 11/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5332 - accuracy: 0.7759 - val_loss: 0.5251 - val_accuracy: 0.7827\n",
      "Epoch 12/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5328 - accuracy: 0.7759 - val_loss: 0.5247 - val_accuracy: 0.7827\n",
      "Epoch 13/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 0.5326 - accuracy: 0.7759 - val_loss: 0.5244 - val_accuracy: 0.7827\n",
      "Epoch 14/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7759 - val_loss: 0.5242 - val_accuracy: 0.7827\n",
      "Epoch 15/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5323 - accuracy: 0.7759 - val_loss: 0.5240 - val_accuracy: 0.7827\n",
      "Epoch 16/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5239 - val_accuracy: 0.7827\n",
      "Epoch 17/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5238 - val_accuracy: 0.7827\n",
      "Epoch 18/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5238 - val_accuracy: 0.7827\n",
      "Epoch 19/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 20/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 21/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 22/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 23/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 24/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 25/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 26/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 27/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 28/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 29/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 30/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 31/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 32/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 33/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 34/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 35/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 36/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 37/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 38/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 39/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 40/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 41/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 42/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 43/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 44/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 45/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 46/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 47/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 48/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 49/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 50/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 51/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 52/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 53/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 54/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 55/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 56/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 57/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 58/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 59/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 60/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 61/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 62/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 63/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 64/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 65/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 66/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 67/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 68/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 69/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 70/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 71/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 72/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 73/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 74/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 75/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 76/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 77/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 78/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 79/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 80/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 81/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 82/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 83/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 84/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 85/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 86/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 87/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 88/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 89/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 90/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 91/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 92/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 93/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 94/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 95/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 96/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 97/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 98/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 99/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 100/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n"
     ]
    }
   ],
   "source": [
    "historySGD = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = historySGD.history['loss'] \n",
    "train_accuracy = historySGD.history['accuracy']  \n",
    "valid_loss = historySGD.history['val_loss'] \n",
    "valid_accuracy = historySGD.history['val_accuracy']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Training Loss: 12.31742000579834, Training Accuracy: 0.7748099565505981\n",
      "  Validation Loss: 0.6232122778892517, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 2:\n",
      "  Training Loss: 0.6043109893798828, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5836120247840881, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 3:\n",
      "  Training Loss: 0.5751526355743408, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5607377886772156, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 4:\n",
      "  Training Loss: 0.5582716464996338, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5470731854438782, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 5:\n",
      "  Training Loss: 0.5482786893844604, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5387941598892212, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 6:\n",
      "  Training Loss: 0.5422456860542297, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5335806012153625, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 7:\n",
      "  Training Loss: 0.5385231375694275, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.530288577079773, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 8:\n",
      "  Training Loss: 0.5362042188644409, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5281332731246948, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 9:\n",
      "  Training Loss: 0.5347340703010559, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.526725172996521, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 10:\n",
      "  Training Loss: 0.5338007807731628, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.525776743888855, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 11:\n",
      "  Training Loss: 0.5332030057907104, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5251467823982239, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 12:\n",
      "  Training Loss: 0.5328211784362793, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5247088670730591, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 13:\n",
      "  Training Loss: 0.532570481300354, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5244011282920837, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 14:\n",
      "  Training Loss: 0.532406210899353, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5241838693618774, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 15:\n",
      "  Training Loss: 0.5322994589805603, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5240317583084106, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 16:\n",
      "  Training Loss: 0.5322311520576477, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5239198803901672, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 17:\n",
      "  Training Loss: 0.532184898853302, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5238386988639832, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 18:\n",
      "  Training Loss: 0.5321558117866516, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237795114517212, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 19:\n",
      "  Training Loss: 0.5321365594863892, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237333178520203, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 20:\n",
      "  Training Loss: 0.5321215987205505, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236954092979431, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 21:\n",
      "  Training Loss: 0.5321131348609924, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236682295799255, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 22:\n",
      "  Training Loss: 0.532106876373291, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236449837684631, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 23:\n",
      "  Training Loss: 0.5321031212806702, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523630678653717, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 24:\n",
      "  Training Loss: 0.5321006178855896, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236195921897888, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 25:\n",
      "  Training Loss: 0.532099723815918, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236121416091919, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 26:\n",
      "  Training Loss: 0.5320989489555359, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236045718193054, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 27:\n",
      "  Training Loss: 0.5320983529090881, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235978960990906, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 28:\n",
      "  Training Loss: 0.5320970416069031, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235921740531921, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 29:\n",
      "  Training Loss: 0.5320971608161926, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235875844955444, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 30:\n",
      "  Training Loss: 0.5320965051651001, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235834717750549, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 31:\n",
      "  Training Loss: 0.5320969223976135, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235803723335266, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 32:\n",
      "  Training Loss: 0.5320971608161926, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235795974731445, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 33:\n",
      "  Training Loss: 0.5320966243743896, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235764980316162, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 34:\n",
      "  Training Loss: 0.5320964455604553, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235740542411804, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 35:\n",
      "  Training Loss: 0.5320966839790344, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235728621482849, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 36:\n",
      "  Training Loss: 0.5320956110954285, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235740542411804, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 37:\n",
      "  Training Loss: 0.5320966839790344, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235720872879028, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 38:\n",
      "  Training Loss: 0.5320961475372314, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235744714736938, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 39:\n",
      "  Training Loss: 0.532096266746521, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235732197761536, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 40:\n",
      "  Training Loss: 0.5320970416069031, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235738754272461, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 41:\n",
      "  Training Loss: 0.5320964455604553, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235740542411804, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 42:\n",
      "  Training Loss: 0.5320969223976135, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235723257064819, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 43:\n",
      "  Training Loss: 0.5320959091186523, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235689878463745, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 44:\n",
      "  Training Loss: 0.5320964455604553, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235702991485596, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 45:\n",
      "  Training Loss: 0.532096266746521, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235691070556641, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 46:\n",
      "  Training Loss: 0.5320963263511658, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235691666603088, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 47:\n",
      "  Training Loss: 0.532096266746521, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523567795753479, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 48:\n",
      "  Training Loss: 0.5320956110954285, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235675573348999, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 49:\n",
      "  Training Loss: 0.532096266746521, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235687494277954, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 50:\n",
      "  Training Loss: 0.5320961475372314, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235687494277954, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 51:\n",
      "  Training Loss: 0.532096266746521, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235676169395447, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 52:\n",
      "  Training Loss: 0.5320956110954285, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235689282417297, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 53:\n",
      "  Training Loss: 0.5320962071418762, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523568868637085, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 54:\n",
      "  Training Loss: 0.5320959091186523, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235681533813477, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 55:\n",
      "  Training Loss: 0.5320963859558105, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235691666603088, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 56:\n",
      "  Training Loss: 0.5320957899093628, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235704183578491, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 57:\n",
      "  Training Loss: 0.5320963263511658, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235676765441895, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 58:\n",
      "  Training Loss: 0.5320956707000732, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235673785209656, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 59:\n",
      "  Training Loss: 0.5320969223976135, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235692262649536, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 60:\n",
      "  Training Loss: 0.5320972204208374, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235703587532043, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 61:\n",
      "  Training Loss: 0.5320964455604553, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235713124275208, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 62:\n",
      "  Training Loss: 0.5320963263511658, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235708355903625, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 63:\n",
      "  Training Loss: 0.5320963263511658, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235716104507446, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 64:\n",
      "  Training Loss: 0.532096266746521, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235700607299805, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 65:\n",
      "  Training Loss: 0.5320952534675598, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235707759857178, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 66:\n",
      "  Training Loss: 0.5320965647697449, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235716104507446, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 67:\n",
      "  Training Loss: 0.5320960283279419, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.52357017993927, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 68:\n",
      "  Training Loss: 0.5320958495140076, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235722661018372, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 69:\n",
      "  Training Loss: 0.532096266746521, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235716104507446, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 70:\n",
      "  Training Loss: 0.5320960283279419, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235686898231506, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 71:\n",
      "  Training Loss: 0.5320964455604553, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235689878463745, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 72:\n",
      "  Training Loss: 0.5320955514907837, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235676169395447, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 73:\n",
      "  Training Loss: 0.5320966839790344, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235694646835327, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 74:\n",
      "  Training Loss: 0.532096266746521, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235694646835327, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 75:\n",
      "  Training Loss: 0.5320959687232971, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235664248466492, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 76:\n",
      "  Training Loss: 0.5320963263511658, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235674977302551, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 77:\n",
      "  Training Loss: 0.5320963263511658, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235689282417297, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 78:\n",
      "  Training Loss: 0.5320956707000732, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235686898231506, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 79:\n",
      "  Training Loss: 0.5320966839790344, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235695242881775, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 80:\n",
      "  Training Loss: 0.5320963859558105, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235722661018372, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 81:\n",
      "  Training Loss: 0.5320960283279419, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235699415206909, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 82:\n",
      "  Training Loss: 0.532096803188324, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523568868637085, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 83:\n",
      "  Training Loss: 0.5320959687232971, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235689878463745, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 84:\n",
      "  Training Loss: 0.5320960879325867, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235686898231506, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 85:\n",
      "  Training Loss: 0.5320958495140076, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235694050788879, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 86:\n",
      "  Training Loss: 0.5320957899093628, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235710740089417, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 87:\n",
      "  Training Loss: 0.5320963859558105, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235708355903625, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 88:\n",
      "  Training Loss: 0.5320963859558105, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235688090324402, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 89:\n",
      "  Training Loss: 0.5320963859558105, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235668420791626, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 90:\n",
      "  Training Loss: 0.5320963263511658, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235686898231506, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 91:\n",
      "  Training Loss: 0.5320954918861389, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235695242881775, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 92:\n",
      "  Training Loss: 0.5320966839790344, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523569643497467, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 93:\n",
      "  Training Loss: 0.5320957899093628, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235695242881775, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 94:\n",
      "  Training Loss: 0.5320958495140076, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235670208930969, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 95:\n",
      "  Training Loss: 0.532096266746521, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235676169395447, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 96:\n",
      "  Training Loss: 0.5320966839790344, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235691070556641, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 97:\n",
      "  Training Loss: 0.532095730304718, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235710144042969, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 98:\n",
      "  Training Loss: 0.5320956707000732, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235714912414551, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 99:\n",
      "  Training Loss: 0.5320961475372314, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235716104507446, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 100:\n",
      "  Training Loss: 0.5320965647697449, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235715508460999, Validation Accuracy: 0.7827280163764954\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(len(train_loss)):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Training Loss: {train_loss[epoch]}, Training Accuracy: {train_accuracy[epoch]}\")\n",
    "    print(f\"  Validation Loss: {valid_loss[epoch]}, Validation Accuracy: {valid_accuracy[epoch]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(5, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 137657.1250 - accuracy: 0.7750 - val_loss: 0.5252 - val_accuracy: 0.7827\n",
      "Epoch 2/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5324 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 3/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 4/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 5/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 6/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 7/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 8/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 9/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 10/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 11/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 12/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 13/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 14/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 15/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 16/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 17/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 18/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 19/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 20/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 21/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 22/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 23/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 24/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 25/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 26/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 27/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 28/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 29/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 30/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 31/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 32/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 33/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 34/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 35/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 36/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 37/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 38/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 39/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 40/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 41/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 42/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 43/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 44/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 45/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 46/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 47/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 48/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 49/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 50/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 51/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 52/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 53/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 54/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 55/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 56/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 57/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 58/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 59/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 60/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 61/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 62/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 63/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 64/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 65/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 66/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 67/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 68/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 69/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 70/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 71/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 72/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 73/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 74/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 75/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 76/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 77/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 78/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 79/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 80/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 81/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 82/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 83/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 84/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 85/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 86/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 87/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 88/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 89/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 90/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 91/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 92/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 93/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 94/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 95/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 96/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 97/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 98/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 99/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 100/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n"
     ]
    }
   ],
   "source": [
    "historySGDM = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = historySGDM.history['loss'] \n",
    "train_accuracy = historySGDM.history['accuracy']  \n",
    "valid_loss = historySGDM.history['val_loss'] \n",
    "valid_accuracy = historySGDM.history['val_accuracy']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Training Loss: 137657.125, Training Accuracy: 0.7750211358070374\n",
      "  Validation Loss: 0.5251956582069397, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 2:\n",
      "  Training Loss: 0.5323540568351746, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236323475837708, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 3:\n",
      "  Training Loss: 0.5321263670921326, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523642897605896, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 4:\n",
      "  Training Loss: 0.5321317315101624, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235294699668884, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 5:\n",
      "  Training Loss: 0.5321221947669983, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236878991127014, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 6:\n",
      "  Training Loss: 0.5321329236030579, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.52354496717453, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 7:\n",
      "  Training Loss: 0.5321378707885742, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236078500747681, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 8:\n",
      "  Training Loss: 0.5321279168128967, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235268473625183, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 9:\n",
      "  Training Loss: 0.5321537852287292, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523566722869873, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 10:\n",
      "  Training Loss: 0.532133162021637, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235036611557007, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 11:\n",
      "  Training Loss: 0.5321173667907715, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236080288887024, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 12:\n",
      "  Training Loss: 0.532139003276825, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236182808876038, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 13:\n",
      "  Training Loss: 0.5321439504623413, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235688090324402, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 14:\n",
      "  Training Loss: 0.5321394205093384, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235574841499329, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 15:\n",
      "  Training Loss: 0.5321305990219116, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236608386039734, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 16:\n",
      "  Training Loss: 0.5321288704872131, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235851407051086, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 17:\n",
      "  Training Loss: 0.5321313738822937, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235899090766907, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 18:\n",
      "  Training Loss: 0.5321334600448608, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.52364581823349, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 19:\n",
      "  Training Loss: 0.5321443676948547, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235670208930969, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 20:\n",
      "  Training Loss: 0.5321174263954163, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235105752944946, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 21:\n",
      "  Training Loss: 0.5321605801582336, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235658288002014, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 22:\n",
      "  Training Loss: 0.5321189761161804, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234876871109009, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 23:\n",
      "  Training Loss: 0.5321297645568848, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236126780509949, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 24:\n",
      "  Training Loss: 0.5321270227432251, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236425399780273, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 25:\n",
      "  Training Loss: 0.5321618914604187, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236834287643433, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 26:\n",
      "  Training Loss: 0.5321329236030579, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523630678653717, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 27:\n",
      "  Training Loss: 0.5321434736251831, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235462188720703, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 28:\n",
      "  Training Loss: 0.5321297645568848, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523590087890625, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 29:\n",
      "  Training Loss: 0.5321335196495056, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235654711723328, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 30:\n",
      "  Training Loss: 0.5321189165115356, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235479474067688, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 31:\n",
      "  Training Loss: 0.5321446061134338, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235639810562134, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 32:\n",
      "  Training Loss: 0.5321359634399414, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236416459083557, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 33:\n",
      "  Training Loss: 0.5321188569068909, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235179662704468, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 34:\n",
      "  Training Loss: 0.5321384072303772, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235203504562378, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 35:\n",
      "  Training Loss: 0.5321577191352844, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235334634780884, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 36:\n",
      "  Training Loss: 0.5321157574653625, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236183404922485, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 37:\n",
      "  Training Loss: 0.5321386456489563, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235476493835449, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 38:\n",
      "  Training Loss: 0.532107412815094, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236929059028625, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 39:\n",
      "  Training Loss: 0.5321320295333862, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235716104507446, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 40:\n",
      "  Training Loss: 0.532131016254425, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236349105834961, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 41:\n",
      "  Training Loss: 0.5321366786956787, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236182808876038, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 42:\n",
      "  Training Loss: 0.5321628451347351, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235793590545654, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 43:\n",
      "  Training Loss: 0.5320980548858643, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234553217887878, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 44:\n",
      "  Training Loss: 0.5321443676948547, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235859751701355, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 45:\n",
      "  Training Loss: 0.5321256518363953, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235151648521423, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 46:\n",
      "  Training Loss: 0.5321496725082397, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235568284988403, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 47:\n",
      "  Training Loss: 0.5321169495582581, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235273241996765, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 48:\n",
      "  Training Loss: 0.5321299433708191, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235256552696228, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 49:\n",
      "  Training Loss: 0.5321341753005981, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235580205917358, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 50:\n",
      "  Training Loss: 0.5321394205093384, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235691666603088, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 51:\n",
      "  Training Loss: 0.5321317911148071, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235368609428406, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 52:\n",
      "  Training Loss: 0.5321298837661743, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523590087890625, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 53:\n",
      "  Training Loss: 0.5321334600448608, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235695242881775, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 54:\n",
      "  Training Loss: 0.5321523547172546, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235422253608704, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 55:\n",
      "  Training Loss: 0.5321227312088013, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235690474510193, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 56:\n",
      "  Training Loss: 0.5321295857429504, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235826373100281, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 57:\n",
      "  Training Loss: 0.5321177244186401, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523524284362793, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 58:\n",
      "  Training Loss: 0.5321345329284668, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235241651535034, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 59:\n",
      "  Training Loss: 0.5321339964866638, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236107707023621, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 60:\n",
      "  Training Loss: 0.5321588516235352, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236627459526062, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 61:\n",
      "  Training Loss: 0.5321336388587952, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236226916313171, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 62:\n",
      "  Training Loss: 0.5321252942085266, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235623717308044, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 63:\n",
      "  Training Loss: 0.5321369767189026, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236237645149231, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 64:\n",
      "  Training Loss: 0.5321305990219116, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235081315040588, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 65:\n",
      "  Training Loss: 0.5321336984634399, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523576557636261, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 66:\n",
      "  Training Loss: 0.5321451425552368, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236197710037231, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 67:\n",
      "  Training Loss: 0.5321229100227356, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235181450843811, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 68:\n",
      "  Training Loss: 0.5321238040924072, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237001180648804, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 69:\n",
      "  Training Loss: 0.5321505665779114, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235413908958435, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 70:\n",
      "  Training Loss: 0.5321104526519775, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234880447387695, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 71:\n",
      "  Training Loss: 0.5321496725082397, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235528349876404, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 72:\n",
      "  Training Loss: 0.5321435928344727, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523515522480011, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 73:\n",
      "  Training Loss: 0.5321292281150818, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235899090766907, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 74:\n",
      "  Training Loss: 0.5321326851844788, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236135721206665, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 75:\n",
      "  Training Loss: 0.5320791006088257, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523465096950531, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 76:\n",
      "  Training Loss: 0.5321473479270935, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235648155212402, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 77:\n",
      "  Training Loss: 0.5321364998817444, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236321687698364, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 78:\n",
      "  Training Loss: 0.5321328043937683, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235639810562134, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 79:\n",
      "  Training Loss: 0.532139003276825, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236601233482361, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 80:\n",
      "  Training Loss: 0.5321426391601562, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523695170879364, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 81:\n",
      "  Training Loss: 0.5321422815322876, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234957933425903, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 82:\n",
      "  Training Loss: 0.5321515798568726, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235536694526672, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 83:\n",
      "  Training Loss: 0.532143235206604, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235702395439148, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 84:\n",
      "  Training Loss: 0.5321222543716431, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523576021194458, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 85:\n",
      "  Training Loss: 0.5321275591850281, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523569643497467, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 86:\n",
      "  Training Loss: 0.5321170687675476, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236662030220032, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 87:\n",
      "  Training Loss: 0.5321426391601562, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235185623168945, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 88:\n",
      "  Training Loss: 0.5321401357650757, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234904885292053, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 89:\n",
      "  Training Loss: 0.5321161150932312, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234775543212891, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 90:\n",
      "  Training Loss: 0.5321313738822937, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235960483551025, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 91:\n",
      "  Training Loss: 0.5321267247200012, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236040353775024, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 92:\n",
      "  Training Loss: 0.5321403741836548, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235753655433655, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 93:\n",
      "  Training Loss: 0.532131016254425, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235663056373596, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 94:\n",
      "  Training Loss: 0.5321145057678223, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235030055046082, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 95:\n",
      "  Training Loss: 0.5321376919746399, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235676765441895, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 96:\n",
      "  Training Loss: 0.5321500897407532, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236005783081055, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 97:\n",
      "  Training Loss: 0.5321345925331116, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236736536026001, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 98:\n",
      "  Training Loss: 0.5321448445320129, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236204862594604, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 99:\n",
      "  Training Loss: 0.532127320766449, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235950946807861, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 100:\n",
      "  Training Loss: 0.5321460962295532, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235990285873413, Validation Accuracy: 0.7827280163764954\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(len(train_loss)):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Training Loss: {train_loss[epoch]}, Training Accuracy: {train_accuracy[epoch]}\")\n",
    "    print(f\"  Validation Loss: {valid_loss[epoch]}, Validation Accuracy: {valid_accuracy[epoch]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADAGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(5, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 85719.2500 - accuracy: 0.2241 - val_loss: 75555.8672 - val_accuracy: 0.2173\n",
      "Epoch 2/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 67516.1719 - accuracy: 0.2241 - val_loss: 62085.7422 - val_accuracy: 0.2173\n",
      "Epoch 3/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 56116.9922 - accuracy: 0.2241 - val_loss: 51998.7891 - val_accuracy: 0.2173\n",
      "Epoch 4/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 47096.1211 - accuracy: 0.2241 - val_loss: 43654.1289 - val_accuracy: 0.2173\n",
      "Epoch 5/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 39438.4297 - accuracy: 0.2241 - val_loss: 36409.6250 - val_accuracy: 0.2173\n",
      "Epoch 6/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 32688.1191 - accuracy: 0.2241 - val_loss: 29934.0938 - val_accuracy: 0.2173\n",
      "Epoch 7/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 26594.6816 - accuracy: 0.2241 - val_loss: 24036.2773 - val_accuracy: 0.2173\n",
      "Epoch 8/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 21003.9102 - accuracy: 0.2241 - val_loss: 18587.1543 - val_accuracy: 0.2173\n",
      "Epoch 9/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 15810.2061 - accuracy: 0.2241 - val_loss: 13499.0293 - val_accuracy: 0.2173\n",
      "Epoch 10/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 10939.9531 - accuracy: 0.2241 - val_loss: 8708.6191 - val_accuracy: 0.2173\n",
      "Epoch 11/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 6338.6592 - accuracy: 0.2241 - val_loss: 4167.4302 - val_accuracy: 0.2173\n",
      "Epoch 12/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1966.1442 - accuracy: 0.2449 - val_loss: 2.5444 - val_accuracy: 0.6955\n",
      "Epoch 13/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.5613 - accuracy: 0.7260 - val_loss: 2.7707 - val_accuracy: 0.7827\n",
      "Epoch 14/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 2.5477 - accuracy: 0.7264 - val_loss: 2.5366 - val_accuracy: 0.7743\n",
      "Epoch 15/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.5549 - accuracy: 0.7276 - val_loss: 2.4414 - val_accuracy: 0.7409\n",
      "Epoch 16/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.5281 - accuracy: 0.7250 - val_loss: 2.5076 - val_accuracy: 0.6949\n",
      "Epoch 17/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 2.5127 - accuracy: 0.7270 - val_loss: 2.4314 - val_accuracy: 0.7508\n",
      "Epoch 18/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.4909 - accuracy: 0.7285 - val_loss: 2.4111 - val_accuracy: 0.7386\n",
      "Epoch 19/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.5077 - accuracy: 0.7255 - val_loss: 2.5207 - val_accuracy: 0.7779\n",
      "Epoch 20/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.4840 - accuracy: 0.7281 - val_loss: 2.3922 - val_accuracy: 0.7401\n",
      "Epoch 21/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.4772 - accuracy: 0.7261 - val_loss: 2.4679 - val_accuracy: 0.7747\n",
      "Epoch 22/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.4509 - accuracy: 0.7251 - val_loss: 2.3786 - val_accuracy: 0.7466\n",
      "Epoch 23/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.4495 - accuracy: 0.7256 - val_loss: 2.4347 - val_accuracy: 0.6957\n",
      "Epoch 24/100\n",
      "592/592 [==============================] - 2s 4ms/step - loss: 2.4511 - accuracy: 0.7257 - val_loss: 2.3618 - val_accuracy: 0.7508\n",
      "Epoch 25/100\n",
      "592/592 [==============================] - 2s 4ms/step - loss: 2.4343 - accuracy: 0.7279 - val_loss: 2.3562 - val_accuracy: 0.7523\n",
      "Epoch 26/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.4235 - accuracy: 0.7241 - val_loss: 2.3688 - val_accuracy: 0.7059\n",
      "Epoch 27/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.4126 - accuracy: 0.7258 - val_loss: 2.3431 - val_accuracy: 0.7561\n",
      "Epoch 28/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.4052 - accuracy: 0.7277 - val_loss: 2.3778 - val_accuracy: 0.7720\n",
      "Epoch 29/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.3915 - accuracy: 0.7248 - val_loss: 2.7063 - val_accuracy: 0.7827\n",
      "Epoch 30/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.3858 - accuracy: 0.7268 - val_loss: 2.3242 - val_accuracy: 0.7625\n",
      "Epoch 31/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.3811 - accuracy: 0.7281 - val_loss: 2.3287 - val_accuracy: 0.7673\n",
      "Epoch 32/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.3686 - accuracy: 0.7262 - val_loss: 2.2811 - val_accuracy: 0.7251\n",
      "Epoch 33/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.3570 - accuracy: 0.7267 - val_loss: 2.2681 - val_accuracy: 0.7401\n",
      "Epoch 34/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.3435 - accuracy: 0.7252 - val_loss: 2.4448 - val_accuracy: 0.6704\n",
      "Epoch 35/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.3491 - accuracy: 0.7264 - val_loss: 2.3203 - val_accuracy: 0.7732\n",
      "Epoch 36/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.3390 - accuracy: 0.7274 - val_loss: 2.2587 - val_accuracy: 0.7572\n",
      "Epoch 37/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.3228 - accuracy: 0.7275 - val_loss: 2.2366 - val_accuracy: 0.7468\n",
      "Epoch 38/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.3210 - accuracy: 0.7277 - val_loss: 2.2406 - val_accuracy: 0.7133\n",
      "Epoch 39/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.2969 - accuracy: 0.7269 - val_loss: 2.2357 - val_accuracy: 0.7606\n",
      "Epoch 40/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.2919 - accuracy: 0.7259 - val_loss: 2.2538 - val_accuracy: 0.7703\n",
      "Epoch 41/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.2901 - accuracy: 0.7283 - val_loss: 2.2857 - val_accuracy: 0.6875\n",
      "Epoch 42/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.2737 - accuracy: 0.7265 - val_loss: 2.1845 - val_accuracy: 0.7340\n",
      "Epoch 43/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.2541 - accuracy: 0.7283 - val_loss: 2.1820 - val_accuracy: 0.7230\n",
      "Epoch 44/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.2589 - accuracy: 0.7265 - val_loss: 2.4089 - val_accuracy: 0.6615\n",
      "Epoch 45/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.2545 - accuracy: 0.7257 - val_loss: 2.2103 - val_accuracy: 0.6987\n",
      "Epoch 46/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.2346 - accuracy: 0.7277 - val_loss: 2.1551 - val_accuracy: 0.7481\n",
      "Epoch 47/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.2240 - accuracy: 0.7271 - val_loss: 2.1494 - val_accuracy: 0.7527\n",
      "Epoch 48/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 2.2214 - accuracy: 0.7273 - val_loss: 2.1443 - val_accuracy: 0.7551\n",
      "Epoch 49/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.1982 - accuracy: 0.7295 - val_loss: 2.3198 - val_accuracy: 0.6668\n",
      "Epoch 50/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.2003 - accuracy: 0.7267 - val_loss: 2.2679 - val_accuracy: 0.7819\n",
      "Epoch 51/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.1917 - accuracy: 0.7256 - val_loss: 2.1597 - val_accuracy: 0.6987\n",
      "Epoch 52/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.1864 - accuracy: 0.7276 - val_loss: 2.1477 - val_accuracy: 0.7713\n",
      "Epoch 53/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.1757 - accuracy: 0.7272 - val_loss: 2.1015 - val_accuracy: 0.7559\n",
      "Epoch 54/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.1674 - accuracy: 0.7274 - val_loss: 2.0764 - val_accuracy: 0.7384\n",
      "Epoch 55/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.1425 - accuracy: 0.7277 - val_loss: 2.2553 - val_accuracy: 0.6679\n",
      "Epoch 56/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.1463 - accuracy: 0.7298 - val_loss: 2.3471 - val_accuracy: 0.6499\n",
      "Epoch 57/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.1425 - accuracy: 0.7268 - val_loss: 2.0729 - val_accuracy: 0.7610\n",
      "Epoch 58/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.1175 - accuracy: 0.7276 - val_loss: 2.0693 - val_accuracy: 0.7099\n",
      "Epoch 59/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.1315 - accuracy: 0.7265 - val_loss: 2.1244 - val_accuracy: 0.6873\n",
      "Epoch 60/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.1218 - accuracy: 0.7276 - val_loss: 2.0248 - val_accuracy: 0.7350\n",
      "Epoch 61/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 2.1003 - accuracy: 0.7261 - val_loss: 2.2793 - val_accuracy: 0.7827\n",
      "Epoch 62/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.0854 - accuracy: 0.7296 - val_loss: 2.0264 - val_accuracy: 0.7595\n",
      "Epoch 63/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.0887 - accuracy: 0.7282 - val_loss: 2.0006 - val_accuracy: 0.7323\n",
      "Epoch 64/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.0788 - accuracy: 0.7264 - val_loss: 1.9909 - val_accuracy: 0.7382\n",
      "Epoch 65/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.0600 - accuracy: 0.7294 - val_loss: 2.0839 - val_accuracy: 0.6856\n",
      "Epoch 66/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.0544 - accuracy: 0.7281 - val_loss: 1.9777 - val_accuracy: 0.7255\n",
      "Epoch 67/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.0450 - accuracy: 0.7273 - val_loss: 1.9831 - val_accuracy: 0.7135\n",
      "Epoch 68/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.0423 - accuracy: 0.7297 - val_loss: 1.9631 - val_accuracy: 0.7232\n",
      "Epoch 69/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.0365 - accuracy: 0.7280 - val_loss: 2.0666 - val_accuracy: 0.6818\n",
      "Epoch 70/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.0192 - accuracy: 0.7284 - val_loss: 1.9612 - val_accuracy: 0.7126\n",
      "Epoch 71/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.0318 - accuracy: 0.7273 - val_loss: 1.9378 - val_accuracy: 0.7496\n",
      "Epoch 72/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 2.0195 - accuracy: 0.7278 - val_loss: 1.9223 - val_accuracy: 0.7382\n",
      "Epoch 73/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.9980 - accuracy: 0.7278 - val_loss: 2.0253 - val_accuracy: 0.6824\n",
      "Epoch 74/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 1.9922 - accuracy: 0.7291 - val_loss: 2.0494 - val_accuracy: 0.6746\n",
      "Epoch 75/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.9903 - accuracy: 0.7269 - val_loss: 1.9069 - val_accuracy: 0.7523\n",
      "Epoch 76/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 1.9669 - accuracy: 0.7277 - val_loss: 1.8909 - val_accuracy: 0.7407\n",
      "Epoch 77/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 1.9634 - accuracy: 0.7293 - val_loss: 1.8952 - val_accuracy: 0.7168\n",
      "Epoch 78/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 1.9606 - accuracy: 0.7275 - val_loss: 1.8737 - val_accuracy: 0.7411\n",
      "Epoch 79/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.9497 - accuracy: 0.7286 - val_loss: 1.9855 - val_accuracy: 0.7815\n",
      "Epoch 80/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.9437 - accuracy: 0.7274 - val_loss: 1.8673 - val_accuracy: 0.7551\n",
      "Epoch 81/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.9275 - accuracy: 0.7284 - val_loss: 1.8642 - val_accuracy: 0.7147\n",
      "Epoch 82/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.9234 - accuracy: 0.7269 - val_loss: 1.8437 - val_accuracy: 0.7464\n",
      "Epoch 83/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.9181 - accuracy: 0.7268 - val_loss: 1.8447 - val_accuracy: 0.7568\n",
      "Epoch 84/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.9063 - accuracy: 0.7284 - val_loss: 2.0474 - val_accuracy: 0.7827\n",
      "Epoch 85/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 1.9040 - accuracy: 0.7280 - val_loss: 1.9338 - val_accuracy: 0.6801\n",
      "Epoch 86/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8894 - accuracy: 0.7284 - val_loss: 1.8949 - val_accuracy: 0.6867\n",
      "Epoch 87/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8926 - accuracy: 0.7286 - val_loss: 1.9050 - val_accuracy: 0.6829\n",
      "Epoch 88/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8876 - accuracy: 0.7276 - val_loss: 1.8736 - val_accuracy: 0.7789\n",
      "Epoch 89/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 1.8614 - accuracy: 0.7303 - val_loss: 1.7983 - val_accuracy: 0.7173\n",
      "Epoch 90/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 1.8673 - accuracy: 0.7279 - val_loss: 1.7925 - val_accuracy: 0.7147\n",
      "Epoch 91/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8507 - accuracy: 0.7272 - val_loss: 1.8191 - val_accuracy: 0.7739\n",
      "Epoch 92/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8339 - accuracy: 0.7282 - val_loss: 1.7648 - val_accuracy: 0.7268\n",
      "Epoch 93/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8474 - accuracy: 0.7286 - val_loss: 1.7919 - val_accuracy: 0.7720\n",
      "Epoch 94/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8243 - accuracy: 0.7284 - val_loss: 1.7446 - val_accuracy: 0.7405\n",
      "Epoch 95/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8094 - accuracy: 0.7294 - val_loss: 1.7561 - val_accuracy: 0.7133\n",
      "Epoch 96/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8202 - accuracy: 0.7299 - val_loss: 1.8029 - val_accuracy: 0.6890\n",
      "Epoch 97/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.8016 - accuracy: 0.7298 - val_loss: 1.7426 - val_accuracy: 0.7116\n",
      "Epoch 98/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 1.7915 - accuracy: 0.7277 - val_loss: 1.7137 - val_accuracy: 0.7424\n",
      "Epoch 99/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.7861 - accuracy: 0.7303 - val_loss: 1.8492 - val_accuracy: 0.6708\n",
      "Epoch 100/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 1.8008 - accuracy: 0.7272 - val_loss: 1.7649 - val_accuracy: 0.6911\n"
     ]
    }
   ],
   "source": [
    "historyADA = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = historyADA.history['loss'] \n",
    "train_accuracy = historyADA.history['accuracy']  \n",
    "valid_loss = historyADA.history['val_loss'] \n",
    "valid_accuracy = historyADA.history['val_accuracy']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Training Loss: 85719.25, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 75555.8671875, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 2:\n",
      "  Training Loss: 67516.171875, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 62085.7421875, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 3:\n",
      "  Training Loss: 56116.9921875, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 51998.7890625, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 4:\n",
      "  Training Loss: 47096.12109375, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 43654.12890625, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 5:\n",
      "  Training Loss: 39438.4296875, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 36409.625, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 6:\n",
      "  Training Loss: 32688.119140625, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 29934.09375, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 7:\n",
      "  Training Loss: 26594.681640625, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 24036.27734375, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 8:\n",
      "  Training Loss: 21003.91015625, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 18587.154296875, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 9:\n",
      "  Training Loss: 15810.2060546875, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 13499.029296875, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 10:\n",
      "  Training Loss: 10939.953125, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 8708.619140625, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 11:\n",
      "  Training Loss: 6338.6591796875, Training Accuracy: 0.22413429617881775\n",
      "  Validation Loss: 4167.43017578125, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 12:\n",
      "  Training Loss: 1966.1441650390625, Training Accuracy: 0.24493242800235748\n",
      "  Validation Loss: 2.544422149658203, Validation Accuracy: 0.6955236196517944\n",
      "Epoch 13:\n",
      "  Training Loss: 2.5613136291503906, Training Accuracy: 0.7259818315505981\n",
      "  Validation Loss: 2.7707157135009766, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 14:\n",
      "  Training Loss: 2.5476889610290527, Training Accuracy: 0.7263513803482056\n",
      "  Validation Loss: 2.536574363708496, Validation Accuracy: 0.7742820978164673\n",
      "Epoch 15:\n",
      "  Training Loss: 2.5548651218414307, Training Accuracy: 0.7276182174682617\n",
      "  Validation Loss: 2.4413609504699707, Validation Accuracy: 0.7409206032752991\n",
      "Epoch 16:\n",
      "  Training Loss: 2.5281453132629395, Training Accuracy: 0.7250316739082336\n",
      "  Validation Loss: 2.5075972080230713, Validation Accuracy: 0.6948902010917664\n",
      "Epoch 17:\n",
      "  Training Loss: 2.5127458572387695, Training Accuracy: 0.7270376086235046\n",
      "  Validation Loss: 2.4313886165618896, Validation Accuracy: 0.7508445978164673\n",
      "Epoch 18:\n",
      "  Training Loss: 2.490888833999634, Training Accuracy: 0.728462815284729\n",
      "  Validation Loss: 2.4111087322235107, Validation Accuracy: 0.7385979890823364\n",
      "Epoch 19:\n",
      "  Training Loss: 2.507689952850342, Training Accuracy: 0.7254539728164673\n",
      "  Validation Loss: 2.5207197666168213, Validation Accuracy: 0.7778716087341309\n",
      "Epoch 20:\n",
      "  Training Loss: 2.483966827392578, Training Accuracy: 0.7281461358070374\n",
      "  Validation Loss: 2.3921754360198975, Validation Accuracy: 0.7400760054588318\n",
      "Epoch 21:\n",
      "  Training Loss: 2.4771528244018555, Training Accuracy: 0.7260873913764954\n",
      "  Validation Loss: 2.4679014682769775, Validation Accuracy: 0.7747043967247009\n",
      "Epoch 22:\n",
      "  Training Loss: 2.4509224891662598, Training Accuracy: 0.7250844836235046\n",
      "  Validation Loss: 2.3785560131073, Validation Accuracy: 0.7466216087341309\n",
      "Epoch 23:\n",
      "  Training Loss: 2.449488878250122, Training Accuracy: 0.7256123423576355\n",
      "  Validation Loss: 2.4347047805786133, Validation Accuracy: 0.6957347989082336\n",
      "Epoch 24:\n",
      "  Training Loss: 2.451108455657959, Training Accuracy: 0.7257179021835327\n",
      "  Validation Loss: 2.3618111610412598, Validation Accuracy: 0.7508445978164673\n",
      "Epoch 25:\n",
      "  Training Loss: 2.4342949390411377, Training Accuracy: 0.7278822064399719\n",
      "  Validation Loss: 2.356212615966797, Validation Accuracy: 0.7523226141929626\n",
      "Epoch 26:\n",
      "  Training Loss: 2.423492193222046, Training Accuracy: 0.7241342663764954\n",
      "  Validation Loss: 2.368757724761963, Validation Accuracy: 0.7058699131011963\n",
      "Epoch 27:\n",
      "  Training Loss: 2.412614107131958, Training Accuracy: 0.7257707118988037\n",
      "  Validation Loss: 2.3431179523468018, Validation Accuracy: 0.7561233043670654\n",
      "Epoch 28:\n",
      "  Training Loss: 2.405195474624634, Training Accuracy: 0.7276710271835327\n",
      "  Validation Loss: 2.3777809143066406, Validation Accuracy: 0.7719594836235046\n",
      "Epoch 29:\n",
      "  Training Loss: 2.3915212154388428, Training Accuracy: 0.7248204946517944\n",
      "  Validation Loss: 2.706251621246338, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 30:\n",
      "  Training Loss: 2.3858230113983154, Training Accuracy: 0.7267736196517944\n",
      "  Validation Loss: 2.3242270946502686, Validation Accuracy: 0.7624577879905701\n",
      "Epoch 31:\n",
      "  Training Loss: 2.3810524940490723, Training Accuracy: 0.7280933260917664\n",
      "  Validation Loss: 2.3287086486816406, Validation Accuracy: 0.7673141956329346\n",
      "Epoch 32:\n",
      "  Training Loss: 2.3686225414276123, Training Accuracy: 0.7261930108070374\n",
      "  Validation Loss: 2.2811386585235596, Validation Accuracy: 0.7250844836235046\n",
      "Epoch 33:\n",
      "  Training Loss: 2.3569905757904053, Training Accuracy: 0.7266680598258972\n",
      "  Validation Loss: 2.2681221961975098, Validation Accuracy: 0.7400760054588318\n",
      "Epoch 34:\n",
      "  Training Loss: 2.343522787094116, Training Accuracy: 0.7252427935600281\n",
      "  Validation Loss: 2.444782018661499, Validation Accuracy: 0.6703969836235046\n",
      "Epoch 35:\n",
      "  Training Loss: 2.3490874767303467, Training Accuracy: 0.7264041304588318\n",
      "  Validation Loss: 2.320277690887451, Validation Accuracy: 0.7732263803482056\n",
      "Epoch 36:\n",
      "  Training Loss: 2.339019775390625, Training Accuracy: 0.7273542881011963\n",
      "  Validation Loss: 2.2587077617645264, Validation Accuracy: 0.7571790814399719\n",
      "Epoch 37:\n",
      "  Training Loss: 2.322772741317749, Training Accuracy: 0.7274599075317383\n",
      "  Validation Loss: 2.2366039752960205, Validation Accuracy: 0.7468327879905701\n",
      "Epoch 38:\n",
      "  Training Loss: 2.321042060852051, Training Accuracy: 0.7277238368988037\n",
      "  Validation Loss: 2.240626335144043, Validation Accuracy: 0.7132601141929626\n",
      "Epoch 39:\n",
      "  Training Loss: 2.2969136238098145, Training Accuracy: 0.7268792390823364\n",
      "  Validation Loss: 2.2357420921325684, Validation Accuracy: 0.7605574131011963\n",
      "Epoch 40:\n",
      "  Training Loss: 2.291881561279297, Training Accuracy: 0.7259290814399719\n",
      "  Validation Loss: 2.2538399696350098, Validation Accuracy: 0.7702702879905701\n",
      "Epoch 41:\n",
      "  Training Loss: 2.290083885192871, Training Accuracy: 0.7283045053482056\n",
      "  Validation Loss: 2.285677909851074, Validation Accuracy: 0.6875\n",
      "Epoch 42:\n",
      "  Training Loss: 2.2736947536468506, Training Accuracy: 0.726509690284729\n",
      "  Validation Loss: 2.1844639778137207, Validation Accuracy: 0.7339527010917664\n",
      "Epoch 43:\n",
      "  Training Loss: 2.2540998458862305, Training Accuracy: 0.7282516956329346\n",
      "  Validation Loss: 2.181978702545166, Validation Accuracy: 0.7229729890823364\n",
      "Epoch 44:\n",
      "  Training Loss: 2.2589356899261475, Training Accuracy: 0.726509690284729\n",
      "  Validation Loss: 2.4088871479034424, Validation Accuracy: 0.6615287065505981\n",
      "Epoch 45:\n",
      "  Training Loss: 2.254481554031372, Training Accuracy: 0.7256650924682617\n",
      "  Validation Loss: 2.2102553844451904, Validation Accuracy: 0.6986908912658691\n",
      "Epoch 46:\n",
      "  Training Loss: 2.2346348762512207, Training Accuracy: 0.7276710271835327\n",
      "  Validation Loss: 2.1550674438476562, Validation Accuracy: 0.748099684715271\n",
      "Epoch 47:\n",
      "  Training Loss: 2.2239632606506348, Training Accuracy: 0.7270903587341309\n",
      "  Validation Loss: 2.149400234222412, Validation Accuracy: 0.7527449131011963\n",
      "Epoch 48:\n",
      "  Training Loss: 2.2213757038116455, Training Accuracy: 0.7273015379905701\n",
      "  Validation Loss: 2.1442604064941406, Validation Accuracy: 0.7550675868988037\n",
      "Epoch 49:\n",
      "  Training Loss: 2.1981542110443115, Training Accuracy: 0.7295185923576355\n",
      "  Validation Loss: 2.3197944164276123, Validation Accuracy: 0.6668074131011963\n",
      "Epoch 50:\n",
      "  Training Loss: 2.200265884399414, Training Accuracy: 0.7267208695411682\n",
      "  Validation Loss: 2.2678894996643066, Validation Accuracy: 0.7818834185600281\n",
      "Epoch 51:\n",
      "  Training Loss: 2.1916964054107666, Training Accuracy: 0.7256123423576355\n",
      "  Validation Loss: 2.159662961959839, Validation Accuracy: 0.6986908912658691\n",
      "Epoch 52:\n",
      "  Training Loss: 2.186366319656372, Training Accuracy: 0.7275654673576355\n",
      "  Validation Loss: 2.1476523876190186, Validation Accuracy: 0.7713260054588318\n",
      "Epoch 53:\n",
      "  Training Loss: 2.175652027130127, Training Accuracy: 0.7271959185600281\n",
      "  Validation Loss: 2.1015288829803467, Validation Accuracy: 0.755912184715271\n",
      "Epoch 54:\n",
      "  Training Loss: 2.167393207550049, Training Accuracy: 0.7274070978164673\n",
      "  Validation Loss: 2.076371192932129, Validation Accuracy: 0.7383868098258972\n",
      "Epoch 55:\n",
      "  Training Loss: 2.142489194869995, Training Accuracy: 0.7276710271835327\n",
      "  Validation Loss: 2.255262613296509, Validation Accuracy: 0.6678631901741028\n",
      "Epoch 56:\n",
      "  Training Loss: 2.146268129348755, Training Accuracy: 0.7298353314399719\n",
      "  Validation Loss: 2.347126007080078, Validation Accuracy: 0.6499155163764954\n",
      "Epoch 57:\n",
      "  Training Loss: 2.142549991607666, Training Accuracy: 0.7268264293670654\n",
      "  Validation Loss: 2.0729408264160156, Validation Accuracy: 0.7609797120094299\n",
      "Epoch 58:\n",
      "  Training Loss: 2.1175217628479004, Training Accuracy: 0.7276182174682617\n",
      "  Validation Loss: 2.0692615509033203, Validation Accuracy: 0.7098817825317383\n",
      "Epoch 59:\n",
      "  Training Loss: 2.131538152694702, Training Accuracy: 0.7264569401741028\n",
      "  Validation Loss: 2.1243953704833984, Validation Accuracy: 0.6872888803482056\n",
      "Epoch 60:\n",
      "  Training Loss: 2.1217992305755615, Training Accuracy: 0.7276182174682617\n",
      "  Validation Loss: 2.0248348712921143, Validation Accuracy: 0.7350084185600281\n",
      "Epoch 61:\n",
      "  Training Loss: 2.1003377437591553, Training Accuracy: 0.7260873913764954\n",
      "  Validation Loss: 2.2793426513671875, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 62:\n",
      "  Training Loss: 2.085374116897583, Training Accuracy: 0.7295713424682617\n",
      "  Validation Loss: 2.0263712406158447, Validation Accuracy: 0.7595016956329346\n",
      "Epoch 63:\n",
      "  Training Loss: 2.0886898040771484, Training Accuracy: 0.7281988859176636\n",
      "  Validation Loss: 2.0006096363067627, Validation Accuracy: 0.7322635054588318\n",
      "Epoch 64:\n",
      "  Training Loss: 2.078838586807251, Training Accuracy: 0.7263513803482056\n",
      "  Validation Loss: 1.9909306764602661, Validation Accuracy: 0.7381756901741028\n",
      "Epoch 65:\n",
      "  Training Loss: 2.060001850128174, Training Accuracy: 0.7293602228164673\n",
      "  Validation Loss: 2.0839056968688965, Validation Accuracy: 0.685599684715271\n",
      "Epoch 66:\n",
      "  Training Loss: 2.054443597793579, Training Accuracy: 0.7280933260917664\n",
      "  Validation Loss: 1.977705717086792, Validation Accuracy: 0.7255067825317383\n",
      "Epoch 67:\n",
      "  Training Loss: 2.044996976852417, Training Accuracy: 0.7273015379905701\n",
      "  Validation Loss: 1.9831252098083496, Validation Accuracy: 0.7134712934494019\n",
      "Epoch 68:\n",
      "  Training Loss: 2.0422909259796143, Training Accuracy: 0.7297297120094299\n",
      "  Validation Loss: 1.9631034135818481, Validation Accuracy: 0.7231841087341309\n",
      "Epoch 69:\n",
      "  Training Loss: 2.0365166664123535, Training Accuracy: 0.7280405163764954\n",
      "  Validation Loss: 2.0666284561157227, Validation Accuracy: 0.6817989945411682\n",
      "Epoch 70:\n",
      "  Training Loss: 2.019235134124756, Training Accuracy: 0.7283572554588318\n",
      "  Validation Loss: 1.9612449407577515, Validation Accuracy: 0.7126266956329346\n",
      "Epoch 71:\n",
      "  Training Loss: 2.0317819118499756, Training Accuracy: 0.7273015379905701\n",
      "  Validation Loss: 1.937766432762146, Validation Accuracy: 0.7495777010917664\n",
      "Epoch 72:\n",
      "  Training Loss: 2.019542694091797, Training Accuracy: 0.7277765870094299\n",
      "  Validation Loss: 1.9223437309265137, Validation Accuracy: 0.7381756901741028\n",
      "Epoch 73:\n",
      "  Training Loss: 1.9980452060699463, Training Accuracy: 0.7278293967247009\n",
      "  Validation Loss: 2.025294303894043, Validation Accuracy: 0.6824324131011963\n",
      "Epoch 74:\n",
      "  Training Loss: 1.9921926259994507, Training Accuracy: 0.7290962934494019\n",
      "  Validation Loss: 2.049417734146118, Validation Accuracy: 0.6746199131011963\n",
      "Epoch 75:\n",
      "  Training Loss: 1.990304708480835, Training Accuracy: 0.7268792390823364\n",
      "  Validation Loss: 1.90692138671875, Validation Accuracy: 0.7523226141929626\n",
      "Epoch 76:\n",
      "  Training Loss: 1.9668630361557007, Training Accuracy: 0.7276710271835327\n",
      "  Validation Loss: 1.8908807039260864, Validation Accuracy: 0.7407094836235046\n",
      "Epoch 77:\n",
      "  Training Loss: 1.9634380340576172, Training Accuracy: 0.7293074131011963\n",
      "  Validation Loss: 1.8951960802078247, Validation Accuracy: 0.716849684715271\n",
      "Epoch 78:\n",
      "  Training Loss: 1.9605826139450073, Training Accuracy: 0.7275126576423645\n",
      "  Validation Loss: 1.8737126588821411, Validation Accuracy: 0.7411317825317383\n",
      "Epoch 79:\n",
      "  Training Loss: 1.9497264623641968, Training Accuracy: 0.7286211848258972\n",
      "  Validation Loss: 1.9855197668075562, Validation Accuracy: 0.7814611196517944\n",
      "Epoch 80:\n",
      "  Training Loss: 1.9436579942703247, Training Accuracy: 0.7273542881011963\n",
      "  Validation Loss: 1.8673440217971802, Validation Accuracy: 0.7550675868988037\n",
      "Epoch 81:\n",
      "  Training Loss: 1.927481770515442, Training Accuracy: 0.7283572554588318\n",
      "  Validation Loss: 1.8642208576202393, Validation Accuracy: 0.7147381901741028\n",
      "Epoch 82:\n",
      "  Training Loss: 1.9234423637390137, Training Accuracy: 0.7269319891929626\n",
      "  Validation Loss: 1.8436955213546753, Validation Accuracy: 0.7464104890823364\n",
      "Epoch 83:\n",
      "  Training Loss: 1.9181019067764282, Training Accuracy: 0.7267736196517944\n",
      "  Validation Loss: 1.8446582555770874, Validation Accuracy: 0.7567567825317383\n",
      "Epoch 84:\n",
      "  Training Loss: 1.9062819480895996, Training Accuracy: 0.7284100651741028\n",
      "  Validation Loss: 2.04742693901062, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 85:\n",
      "  Training Loss: 1.9040400981903076, Training Accuracy: 0.7280405163764954\n",
      "  Validation Loss: 1.933842658996582, Validation Accuracy: 0.6801097989082336\n",
      "Epoch 86:\n",
      "  Training Loss: 1.8893777132034302, Training Accuracy: 0.7283572554588318\n",
      "  Validation Loss: 1.8948756456375122, Validation Accuracy: 0.6866554021835327\n",
      "Epoch 87:\n",
      "  Training Loss: 1.8925670385360718, Training Accuracy: 0.7286211848258972\n",
      "  Validation Loss: 1.904955267906189, Validation Accuracy: 0.6828547120094299\n",
      "Epoch 88:\n",
      "  Training Loss: 1.887594223022461, Training Accuracy: 0.7276182174682617\n",
      "  Validation Loss: 1.8736499547958374, Validation Accuracy: 0.7789273858070374\n",
      "Epoch 89:\n",
      "  Training Loss: 1.8614182472229004, Training Accuracy: 0.7302576303482056\n",
      "  Validation Loss: 1.7983417510986328, Validation Accuracy: 0.7172719836235046\n",
      "Epoch 90:\n",
      "  Training Loss: 1.8673404455184937, Training Accuracy: 0.7278822064399719\n",
      "  Validation Loss: 1.7925398349761963, Validation Accuracy: 0.7147381901741028\n",
      "Epoch 91:\n",
      "  Training Loss: 1.850737452507019, Training Accuracy: 0.7271959185600281\n",
      "  Validation Loss: 1.8191165924072266, Validation Accuracy: 0.7738597989082336\n",
      "Epoch 92:\n",
      "  Training Loss: 1.8339487314224243, Training Accuracy: 0.7281988859176636\n",
      "  Validation Loss: 1.7647936344146729, Validation Accuracy: 0.7267736196517944\n",
      "Epoch 93:\n",
      "  Training Loss: 1.8473694324493408, Training Accuracy: 0.7286211848258972\n",
      "  Validation Loss: 1.7918585538864136, Validation Accuracy: 0.7719594836235046\n",
      "Epoch 94:\n",
      "  Training Loss: 1.8243253231048584, Training Accuracy: 0.7284100651741028\n",
      "  Validation Loss: 1.7446340322494507, Validation Accuracy: 0.7404983043670654\n",
      "Epoch 95:\n",
      "  Training Loss: 1.8094443082809448, Training Accuracy: 0.7294130325317383\n",
      "  Validation Loss: 1.7560993432998657, Validation Accuracy: 0.7132601141929626\n",
      "Epoch 96:\n",
      "  Training Loss: 1.8202362060546875, Training Accuracy: 0.7298880815505981\n",
      "  Validation Loss: 1.8029483556747437, Validation Accuracy: 0.6889780163764954\n",
      "Epoch 97:\n",
      "  Training Loss: 1.801586627960205, Training Accuracy: 0.7297825217247009\n",
      "  Validation Loss: 1.7425765991210938, Validation Accuracy: 0.7115709185600281\n",
      "Epoch 98:\n",
      "  Training Loss: 1.7914637327194214, Training Accuracy: 0.7277238368988037\n",
      "  Validation Loss: 1.713669776916504, Validation Accuracy: 0.7423986196517944\n",
      "Epoch 99:\n",
      "  Training Loss: 1.7861313819885254, Training Accuracy: 0.7302576303482056\n",
      "  Validation Loss: 1.8492159843444824, Validation Accuracy: 0.6708192825317383\n",
      "Epoch 100:\n",
      "  Training Loss: 1.8008476495742798, Training Accuracy: 0.7272487282752991\n",
      "  Validation Loss: 1.764870285987854, Validation Accuracy: 0.6910895109176636\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(len(train_loss)):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Training Loss: {train_loss[epoch]}, Training Accuracy: {train_accuracy[epoch]}\")\n",
    "    print(f\"  Validation Loss: {valid_loss[epoch]}, Validation Accuracy: {valid_accuracy[epoch]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(5, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9,\n",
    "                                     beta_2=0.999)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 36.9852 - accuracy: 0.6864 - val_loss: 8.5873 - val_accuracy: 0.7827\n",
      "Epoch 2/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 4.9406 - accuracy: 0.6788 - val_loss: 8.5563 - val_accuracy: 0.2173\n",
      "Epoch 3/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 3.9622 - accuracy: 0.6809 - val_loss: 4.0426 - val_accuracy: 0.2173\n",
      "Epoch 4/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 2.4032 - accuracy: 0.6759 - val_loss: 1.8942 - val_accuracy: 0.7827\n",
      "Epoch 5/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 1.4864 - accuracy: 0.6748 - val_loss: 0.9475 - val_accuracy: 0.7821\n",
      "Epoch 6/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.7767 - accuracy: 0.6856 - val_loss: 0.5446 - val_accuracy: 0.7663\n",
      "Epoch 7/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.6844 - accuracy: 0.7185 - val_loss: 0.5370 - val_accuracy: 0.7821\n",
      "Epoch 8/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5834 - accuracy: 0.7655 - val_loss: 0.5238 - val_accuracy: 0.7827\n",
      "Epoch 9/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7759 - val_loss: 0.5141 - val_accuracy: 0.7827\n",
      "Epoch 10/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7759 - val_loss: 0.5126 - val_accuracy: 0.7827\n",
      "Epoch 11/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.7759 - val_loss: 0.5154 - val_accuracy: 0.7827\n",
      "Epoch 12/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5255 - accuracy: 0.7759 - val_loss: 0.5103 - val_accuracy: 0.7827\n",
      "Epoch 13/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7759 - val_loss: 0.5151 - val_accuracy: 0.7827\n",
      "Epoch 14/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5250 - accuracy: 0.7759 - val_loss: 0.5091 - val_accuracy: 0.7827\n",
      "Epoch 15/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7759 - val_loss: 0.5287 - val_accuracy: 0.7827\n",
      "Epoch 16/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 17/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 18/100\n",
      "592/592 [==============================] - 2s 4ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 19/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 20/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 21/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 22/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 23/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 24/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 25/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 26/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 27/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 28/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 29/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 30/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 31/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 32/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 33/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 34/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 35/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 36/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 37/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 38/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 39/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 40/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 41/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 42/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 43/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5234 - val_accuracy: 0.7827\n",
      "Epoch 44/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 45/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 46/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 47/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 48/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 49/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 50/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 51/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 52/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 53/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 54/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 55/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 56/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 57/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 58/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 59/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 60/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 61/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 62/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 63/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 64/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 65/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 66/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 67/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 68/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5238 - val_accuracy: 0.7827\n",
      "Epoch 69/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 70/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 71/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 72/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 73/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 74/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 75/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5234 - val_accuracy: 0.7827\n",
      "Epoch 76/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 77/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 78/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 79/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 80/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 81/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 82/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 83/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 84/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 85/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 86/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 87/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 88/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 89/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 90/100\n",
      "592/592 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 91/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 92/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 93/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 94/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5235 - val_accuracy: 0.7827\n",
      "Epoch 95/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 96/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 97/100\n",
      "592/592 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5237 - val_accuracy: 0.7827\n",
      "Epoch 98/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 99/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n",
      "Epoch 100/100\n",
      "592/592 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7759 - val_loss: 0.5236 - val_accuracy: 0.7827\n"
     ]
    }
   ],
   "source": [
    "historyADM = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = historyADM.history['loss'] \n",
    "train_accuracy = historyADM.history['accuracy']  \n",
    "valid_loss = historyADM.history['val_loss'] \n",
    "valid_accuracy = historyADM.history['val_accuracy']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Training Loss: 36.985172271728516, Training Accuracy: 0.6864442825317383\n",
      "  Validation Loss: 8.587262153625488, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 2:\n",
      "  Training Loss: 4.940552711486816, Training Accuracy: 0.6787900924682617\n",
      "  Validation Loss: 8.556319236755371, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 3:\n",
      "  Training Loss: 3.9622154235839844, Training Accuracy: 0.6809015870094299\n",
      "  Validation Loss: 4.042611598968506, Validation Accuracy: 0.21727195382118225\n",
      "Epoch 4:\n",
      "  Training Loss: 2.4031715393066406, Training Accuracy: 0.6758868098258972\n",
      "  Validation Loss: 1.8942384719848633, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 5:\n",
      "  Training Loss: 1.4863942861557007, Training Accuracy: 0.6748310923576355\n",
      "  Validation Loss: 0.9474893808364868, Validation Accuracy: 0.7820945978164673\n",
      "Epoch 6:\n",
      "  Training Loss: 0.7767313122749329, Training Accuracy: 0.685599684715271\n",
      "  Validation Loss: 0.5445697903633118, Validation Accuracy: 0.7662584185600281\n",
      "Epoch 7:\n",
      "  Training Loss: 0.6843593716621399, Training Accuracy: 0.7184860706329346\n",
      "  Validation Loss: 0.5370252728462219, Validation Accuracy: 0.7820945978164673\n",
      "Epoch 8:\n",
      "  Training Loss: 0.5834034085273743, Training Accuracy: 0.7655194401741028\n",
      "  Validation Loss: 0.5238394141197205, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 9:\n",
      "  Training Loss: 0.5362326502799988, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5140538215637207, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 10:\n",
      "  Training Loss: 0.5257992744445801, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5126320719718933, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 11:\n",
      "  Training Loss: 0.5225217938423157, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5154470801353455, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 12:\n",
      "  Training Loss: 0.5254577994346619, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5103246569633484, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 13:\n",
      "  Training Loss: 0.5226803421974182, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5151060223579407, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 14:\n",
      "  Training Loss: 0.5250048637390137, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5091132521629333, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 15:\n",
      "  Training Loss: 0.5275927186012268, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5286852121353149, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 16:\n",
      "  Training Loss: 0.5327909588813782, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236832499504089, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 17:\n",
      "  Training Loss: 0.5321488380432129, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235937237739563, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 18:\n",
      "  Training Loss: 0.5321453213691711, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236654877662659, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 19:\n",
      "  Training Loss: 0.5321590304374695, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235635638237, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 20:\n",
      "  Training Loss: 0.5321232080459595, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234940052032471, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 21:\n",
      "  Training Loss: 0.5321817398071289, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235627889633179, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 22:\n",
      "  Training Loss: 0.5321263074874878, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234716534614563, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 23:\n",
      "  Training Loss: 0.5321393013000488, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236409902572632, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 24:\n",
      "  Training Loss: 0.5321395993232727, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236764550209045, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 25:\n",
      "  Training Loss: 0.5321828722953796, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237369537353516, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 26:\n",
      "  Training Loss: 0.5321451425552368, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236420631408691, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 27:\n",
      "  Training Loss: 0.5321592092514038, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235307216644287, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 28:\n",
      "  Training Loss: 0.5321386456489563, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235886573791504, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 29:\n",
      "  Training Loss: 0.5321484804153442, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235611796379089, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 30:\n",
      "  Training Loss: 0.5321279764175415, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235345959663391, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 31:\n",
      "  Training Loss: 0.5321635007858276, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523564338684082, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 32:\n",
      "  Training Loss: 0.5321472883224487, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236719250679016, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 33:\n",
      "  Training Loss: 0.5321241617202759, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235024690628052, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 34:\n",
      "  Training Loss: 0.5321531295776367, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235081315040588, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 35:\n",
      "  Training Loss: 0.532179057598114, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235171318054199, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 36:\n",
      "  Training Loss: 0.5321229696273804, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236482620239258, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 37:\n",
      "  Training Loss: 0.5321497917175293, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235236287117004, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 38:\n",
      "  Training Loss: 0.5321058630943298, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237472653388977, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 39:\n",
      "  Training Loss: 0.5321443676948547, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235639214515686, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 40:\n",
      "  Training Loss: 0.5321418642997742, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236471891403198, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 41:\n",
      "  Training Loss: 0.5321493744850159, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236402750015259, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 42:\n",
      "  Training Loss: 0.5321835279464722, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235762596130371, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 43:\n",
      "  Training Loss: 0.5320913195610046, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234355926513672, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 44:\n",
      "  Training Loss: 0.5321576595306396, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236063599586487, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 45:\n",
      "  Training Loss: 0.5321348309516907, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234934687614441, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 46:\n",
      "  Training Loss: 0.5321687459945679, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235663056373596, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 47:\n",
      "  Training Loss: 0.5321243405342102, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235105752944946, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 48:\n",
      "  Training Loss: 0.5321398973464966, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235152244567871, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 49:\n",
      "  Training Loss: 0.532149076461792, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235568284988403, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 50:\n",
      "  Training Loss: 0.5321522951126099, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235565900802612, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 51:\n",
      "  Training Loss: 0.5321457982063293, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235326290130615, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 52:\n",
      "  Training Loss: 0.5321421027183533, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236033797264099, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 53:\n",
      "  Training Loss: 0.5321491956710815, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235603451728821, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 54:\n",
      "  Training Loss: 0.532173752784729, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235362648963928, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 55:\n",
      "  Training Loss: 0.5321340560913086, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235634446144104, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 56:\n",
      "  Training Loss: 0.5321428179740906, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235989689826965, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 57:\n",
      "  Training Loss: 0.5321224927902222, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235098600387573, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 58:\n",
      "  Training Loss: 0.5321478843688965, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235193371772766, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 59:\n",
      "  Training Loss: 0.532145619392395, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236523151397705, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 60:\n",
      "  Training Loss: 0.532180666923523, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237018465995789, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 61:\n",
      "  Training Loss: 0.5321462750434875, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236364603042603, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 62:\n",
      "  Training Loss: 0.5321320295333862, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235640406608582, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 63:\n",
      "  Training Loss: 0.5321495532989502, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236272811889648, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 64:\n",
      "  Training Loss: 0.5321413278579712, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523487389087677, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 65:\n",
      "  Training Loss: 0.5321470499038696, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235905051231384, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 66:\n",
      "  Training Loss: 0.5321648120880127, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523632824420929, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 67:\n",
      "  Training Loss: 0.5321326851844788, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523493766784668, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 68:\n",
      "  Training Loss: 0.5321292281150818, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237897634506226, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 69:\n",
      "  Training Loss: 0.5321729779243469, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235162377357483, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 70:\n",
      "  Training Loss: 0.5321168899536133, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234654545783997, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 71:\n",
      "  Training Loss: 0.5321681499481201, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235609412193298, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 72:\n",
      "  Training Loss: 0.5321581363677979, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.52350252866745, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 73:\n",
      "  Training Loss: 0.5321412086486816, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236045718193054, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 74:\n",
      "  Training Loss: 0.5321444869041443, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236301422119141, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 75:\n",
      "  Training Loss: 0.5320684313774109, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234440565109253, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 76:\n",
      "  Training Loss: 0.5321661829948425, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235739946365356, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 77:\n",
      "  Training Loss: 0.5321511030197144, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236520767211914, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 78:\n",
      "  Training Loss: 0.5321463942527771, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235612988471985, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 79:\n",
      "  Training Loss: 0.5321504473686218, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237180590629578, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 80:\n",
      "  Training Loss: 0.5321605205535889, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523749828338623, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 81:\n",
      "  Training Loss: 0.532151997089386, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234636664390564, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 82:\n",
      "  Training Loss: 0.5321733355522156, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235450267791748, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 83:\n",
      "  Training Loss: 0.5321598052978516, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235811471939087, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 84:\n",
      "  Training Loss: 0.5321323275566101, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235803723335266, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 85:\n",
      "  Training Loss: 0.5321413278579712, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235620141029358, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 86:\n",
      "  Training Loss: 0.5321217179298401, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237371921539307, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 87:\n",
      "  Training Loss: 0.5321615934371948, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234884023666382, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 88:\n",
      "  Training Loss: 0.5321550369262695, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234678387641907, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 89:\n",
      "  Training Loss: 0.5321127772331238, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.523450493812561, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 90:\n",
      "  Training Loss: 0.5321438908576965, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236120820045471, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 91:\n",
      "  Training Loss: 0.5321367383003235, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236296057701111, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 92:\n",
      "  Training Loss: 0.5321564674377441, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235728621482849, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 93:\n",
      "  Training Loss: 0.5321435928344727, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235689878463745, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 94:\n",
      "  Training Loss: 0.5321180820465088, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5234883427619934, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 95:\n",
      "  Training Loss: 0.5321534276008606, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235703587532043, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 96:\n",
      "  Training Loss: 0.5321680307388306, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236204266548157, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 97:\n",
      "  Training Loss: 0.532146155834198, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5237352848052979, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 98:\n",
      "  Training Loss: 0.5321638584136963, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236295461654663, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 99:\n",
      "  Training Loss: 0.5321384072303772, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5235902070999146, Validation Accuracy: 0.7827280163764954\n",
      "Epoch 100:\n",
      "  Training Loss: 0.5321635007858276, Training Accuracy: 0.7758657336235046\n",
      "  Validation Loss: 0.5236086845397949, Validation Accuracy: 0.7827280163764954\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(len(train_loss)):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Training Loss: {train_loss[epoch]}, Training Accuracy: {train_accuracy[epoch]}\")\n",
    "    print(f\"  Validation Loss: {valid_loss[epoch]}, Validation Accuracy: {valid_accuracy[epoch]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for loss in (\"loss\", \"val_loss\"):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    opt_names = \"SGD Momentum AdaGrad Adam\"\n",
    "    for history, opt_name in zip((historySGD, historySGDM,\n",
    "                                  historyADA, historyADM,\n",
    "                                 ),\n",
    "                                 opt_names.split()):\n",
    "        plt.plot(history.history[loss], label=f\"{opt_name}\", linewidth=3)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel({\"loss\": \"Training loss\", \"val_loss\": \"Validation loss\"}[loss])\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.axis([0, 10, 0.5, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar ultimo modelo que fue el mejor\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
